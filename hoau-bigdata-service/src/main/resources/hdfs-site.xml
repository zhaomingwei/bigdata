<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<!--
  Licensed under the Apache License, Version 2.0 (the "License");
  you may not use this file except in compliance with the License.
  You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

  Unless required by applicable law or agreed to in writing, software
  distributed under the License is distributed on an "AS IS" BASIS,
  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  See the License for the specific language governing permissions and
  limitations under the License. See accompanying LICENSE file.
-->

<!-- Put site-specific property overrides in this file. -->

<configuration>
	<!-- 集群名 -->
	<property>
		<name>dfs.nameservices</name>
		<value>cluster</value>
	</property>
	<!-- nameservice 包含哪些namenode，为各个namenode起名 -->
	<!--设置namenodes及其ip:port,注意namenode刚开始的主备关系并没在配置文件中而是取决于在哪一台机器上执行namenode启动的命令-->
	<property>
		<name>dfs.ha.namenodes.cluster</name>
		<value>nn01,nn02</value>
	</property>
	<!-- nn01的RPC通信-->
	<property>
		<name>dfs.namenode.rpc-address.cluster.nn01</name>
		<value>10.39.250.105:9000</value>
		<!--<value>10.39.251.141:9000</value>-->
		<!--<value>192.168.192.121:9000</value>-->
	</property>
	<!-- nn01的http通讯 -->
	<property>
		<name>dfs.namenode.http-address.cluster.nn01</name>
		<value>10.39.250.105:9870</value>
		<!--<value>10.39.251.141:9870</value>-->
		<!--<value>192.168.192.121:9870</value>-->
	</property>
	<!-- nn02的RPC通信 -->
	<property>
		<name>dfs.namenode.rpc-address.cluster.nn02</name>
		<value>10.39.250.106:9000</value>
		<!--<value>10.39.251.122:9000</value>-->
		<!--<value>192.168.192.122:9000</value>-->
	</property>
	<!-- nn02的http通讯 -->
	<property>
		<name>dfs.namenode.http-address.cluster.nn02</name>
		<value>10.39.250.106:9870</value>
		<!--<value>10.39.251.122:9870</value>-->
		<!--<value>192.168.192.122:9870</value>-->
	</property>
	<!--指定namenode的元数据在JournalNode上的存放位置-->
	<property>
		<name>dfs.namenode.shared.edits.dir</name>
		<value>qjournal://10.39.250.105:8485;10.39.250.106:8485;10.39.250.107:8485/cluster</value>
		<!--<value>qjournal://10.39.251.141:8485;10.39.251.122:8485;10.39.251.123:8485/cluster</value>-->
		<!--<value>qjournal://192.168.192.121:8485;192.168.192.122:8485;192.168.192.123:8485/cluster</value>-->
	</property>
	<!-- journalnode 用于存放本地目录-->
	<property>
		<name>dfs.journalnode.edits.dir</name>
		<value>/opt/data/hadoop/journal</value>
	</property>
	<!-- 指定该集群出现故障时，是否自动切换到另一台namenode -->
	<property>
		<name>dfs.ha.automatic-failover.enabled</name>
		<value>true</value>
	</property>
	<!-- 配置失败自动切换实现方式 -->
	<property>
		<name>dfs.client.failover.proxy.provider.cluster</name>
		<value>org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider</value>
	</property>
	<!--切换隔离机制-->
	<property>
		<name>dfs.ha.fencing.methods</name>
		<value>
			sshfence
			shell(/bin/true)
		</value>
	</property>
	<!-- 使用隔离机制需要ssh免密登录 -->
	<property>
		<name>dfs.ha.fencing.ssh.private-key-files</name>
		<value>/root/.ssh/id_rsa</value>
	</property>
	<!-- 配置namenode存放元数据的目录 -->
	<property>
		<name>dfs.namenode.name.dir</name>
		<value>/opt/data/hadoop/name</value>
	</property>
	<!-- 配置datanode存放元数据的目录 -->
	<property>
		<name>dfs.datanode.data.dir</name>
		<value>/opt/data/hadoop/data</value>
	</property>
	<!--指定HDFS副本的数量,不能超过机器节点数-->
	<property>
		<name>dfs.replication</name>
		<value>3</value>
	</property>
	<!--设置用户的操作权限，false标识关闭权限验证，任何用户都可以操作-->
	<property>
		<name>dfs.permissions</name>
		<value>false</value>
	</property>
	
</configuration>
